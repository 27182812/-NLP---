{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用PaddleNLP生成式API搭建一个聊天机器人\n",
    "\n",
    "近年来，人机对话系统受到了学术界和产业界的广泛关注并取得了不错的发展。开放域对话系统旨在建立一个开放域的多轮对话系统，使得机器可以流畅自然地与人进行语言交互，既可以进行日常问候类的闲聊，又可以完成特定功能，以使得开放域对话系统具有实际应用价值。\n",
    "\n",
    "本实例将重点介绍PaddleNLP内置的**生成式API**的功能和用法，并使用PaddleNLP内置的**plato-mini模型**和配套的**生成式API**实现一个简单的闲聊机器人。\n",
    "\n",
    "## 环境要求\n",
    "\n",
    "* PaddlePaddle\n",
    "\n",
    "   本项目依赖于 PaddlePaddle 2.0 及以上版本，请参考 [安装指南](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html) 进行安装\n",
    "\n",
    "* PaddleNLP \n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "   ```\n",
    "* sentencepiece \n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade sentencepiece -i https://pypi.org/simple\n",
    "   ```\n",
    "\n",
    "* Python\n",
    "\n",
    "    Python的版本要求 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "AI Studio平台后续会默认安装PaddleNLP，在此之前可使用如下命令安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e1/f071c0952ffffff18e821b5f3d47a534aadd0ba83e8a8ced4dfdb5534874/paddlenlp-2.0.4-py3-none-any.whl (435kB)\n",
      "\u001b[K     |████████████████████████████████| 440kB 41kB/s eta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (7.2.0)\n",
      "Installing collected packages: paddlenlp\n",
      "  Found existing installation: paddlenlp 2.0.1\n",
      "    Uninstalling paddlenlp-2.0.1:\n",
      "      Successfully uninstalled paddlenlp-2.0.1\n",
      "Successfully installed paddlenlp-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/cd/82/04e9aaf603fdbaecb4323b9e723f13c92c245f6ab2902195c53987848c78/pip-21.1.2-py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 15.0MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.2.3\n",
      "    Uninstalling pip-19.2.3:\n",
      "      Successfully uninstalled pip-19.2.3\n",
      "Successfully installed pip-21.1.2\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.1.85)\n",
      "Collecting sentencepiece\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 20.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.85\n",
      "    Uninstalling sentencepiece-0.1.85:\n",
      "      Successfully uninstalled sentencepiece-0.1.85\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\r\n",
    "!pip install --upgrade sentencepiece "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 生成式API\n",
    "\n",
    "**PaddleNLP针对生成式任务提供了`generate()`函数，内嵌于PaddleNLP所有的生成式模型。支持Greedy Search、Beam Search和Sampling解码策略，用户只需指定解码策略以及相应的参数即可完成预测解码，得到生成的sequence的token ids以及概率得分。**\n",
    "\n",
    "下面给大家展示一个GPT模型使用生成API的例子："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 加载 `paddlenlp.transformers.GPTChineseTokenizer`用于数据处理\n",
    "\n",
    "文本数据在输入预训练模型之前，需要经过数据处理转化为Feature。这一过程通常包括分词，token to id，add special token等步骤。  \n",
    "\n",
    "**PaddleNLP对于各种预训练模型已经内置了相应的tokenizer**，指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "调用`GPTChineseTokenizer`的`__call__`方法即可将我们说的话转为模型可接受的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-25 23:31:34,283] [    INFO] - Downloading gpt-cpm-cn-sentencepiece.model from https://paddlenlp.bj.bcebos.com/models/transformers/gpt/gpt-cpm-cn-sentencepiece.model\n",
      "100%|██████████| 697/697 [00:00<00:00, 8828.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import GPTChineseTokenizer\r\n",
    "\r\n",
    "# 设置想要使用模型的名称\r\n",
    "model_name = 'gpt-cpm-small-cn-distill'\r\n",
    "tokenizer = GPTChineseTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2683, 6102, 241, 400, 7962, 3357, 8, 9]\n",
      "Tensor(shape=[1, 8], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[2683, 6102, 241 , 400 , 7962, 3357, 8   , 9   ]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "\r\n",
    "user_input = \"莫愁前路无知己，\"\r\n",
    "\r\n",
    "# 将文本转为ids\r\n",
    "input_ids = tokenizer(user_input)['input_ids']\r\n",
    "print(input_ids)\r\n",
    "\r\n",
    "# 将转换好的id转为tensor\r\n",
    "input_ids = paddle.to_tensor(input_ids, dtype='int64').unsqueeze(0)\r\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "**PaddleNLP提供了GPT,UnifiedTransformer等中文预训练模型，可以通过预训练模型名称完成一键加载。**\n",
    "\n",
    "GPT以Transformer Decoder的编码器为网络基本组件，采用单向注意力机制，适用于长文本生成任务。\n",
    "\n",
    "PaddleNLP目前提供多种中英文GPT预训练模型，我们这次用的是一个小的中文GPT预训练模型。其他预训练模型请参考[模型列表](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-25 23:33:26,544] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/gpt-cpm-small-cn-distill/gpt-cpm-small-cn-distill.pdparams\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "parameter name [word_embeddings] have be been used. In dygraph mode, the name of parameter can't be same.Please check the parameter attr value passed to self.create_parameter or constructor of dygraph Layers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f4bd362b2594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 一键加载中文GPT模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTLMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/model_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_parameters_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0mbase_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbase_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbase_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbase_arg_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mderived_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase_arg_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/utils.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# keep full configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;31m# registed helper by `_wrap_init`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhelp_func\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/gpt/modeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, hidden_size, num_hidden_layers, num_attention_heads, intermediate_size, hidden_act, hidden_dropout_prob, attention_probs_dropout_prob, max_position_embeddings, type_vocab_size, initializer_range, pad_token_id, eos_token_id, bos_token_id, eol_token_id, topo)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dropout_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mmax_position_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             topo)\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mdecoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/gpt/modeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, hidden_size, hidden_dropout_prob, max_position_embeddings, type_vocab_size, initializer_range, topo)\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"word_embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 initializer=nn.initializer.Normal(\n\u001b[0;32m--> 436\u001b[0;31m                     mean=0.0, std=initializer_range)))\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m#    self.word_embeddings = paddlenlp.ops.ParallelEmbedding(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, sparse, weight_attr, name)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m             is_bias=False)\n\u001b[0m\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0min_dygraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36mcreate_parameter\u001b[0;34m(self, shape, attr, dtype, is_bias, default_initializer)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mtemp_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         return self._helper.create_parameter(temp_attr, shape, dtype, is_bias,\n\u001b[0;32m--> 412\u001b[0;31m                                              default_initializer)\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     @deprecated(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper_base.py\u001b[0m in \u001b[0;36mcreate_parameter\u001b[0;34m(self, attr, shape, dtype, is_bias, default_initializer, stop_gradient, type)\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0;34m\"In dygraph mode, the name of parameter can't be same.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0;34m\"Please check the parameter attr value passed to self.create_parameter or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                     \"constructor of dygraph Layers\".format(attr.name))\n\u001b[0m\u001b[1;32m    369\u001b[0m             return self.main_program.global_block().create_parameter(\n\u001b[1;32m    370\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: parameter name [word_embeddings] have be been used. In dygraph mode, the name of parameter can't be same.Please check the parameter attr value passed to self.create_parameter or constructor of dygraph Layers"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import GPTLMHeadModel\r\n",
    "\r\n",
    "# 一键加载中文GPT模型\r\n",
    "model = GPTLMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1, 16], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[8 , 10, 8 , 10, 8 , 10, 8 , 10, 8 , 10, 8 , 10, 8 , 10, 8 , 10]])\n",
      "Tensor(shape=[1, 1], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[-0.57972622]])\n"
     ]
    }
   ],
   "source": [
    "# 调用生成API升成文本\r\n",
    "ids, scores = model.generate(\r\n",
    "                input_ids=input_ids,\r\n",
    "                max_length=16,\r\n",
    "                min_length=1,\r\n",
    "                decode_strategy='greedy_search')\r\n",
    "\r\n",
    "print(ids)\r\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n"
     ]
    }
   ],
   "source": [
    "generated_ids = ids[0].numpy().tolist()\r\n",
    "\r\n",
    "# 使用tokenizer将生成的id转为文本\r\n",
    "generated_text = tokenizer.convert_ids_to_string(generated_ids)\r\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "可以看到生成的效果还不错，生成式API的用法也是非常的简便。\n",
    "\n",
    "下面我们来展示一下如何使用UnifiedTransformer模型和生成式API完成闲聊对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 加载 `paddlenlp.transformers.UnifiedTransformerTokenizer`用于数据处理\n",
    "\n",
    "`UnifiedTransformerTokenizer`的调用方式与GPT相同，但数据处理的API略有不同。\n",
    "\n",
    "调用`UnifiedTransformerTokenizer`的`dialogue_encode`方法即可将我们说的话转为模型可接受的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-25 23:33:47,981] [    INFO] - Downloading plato-mini-vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/unified_transformer/plato-mini-vocab.txt\n",
      "100%|██████████| 410/410 [00:00<00:00, 3748.39it/s]\n",
      "[2021-06-25 23:33:48,182] [    INFO] - Downloading plato-mini-spm.model from https://paddlenlp.bj.bcebos.com/models/transformers/unified_transformer/plato-mini-spm.model\n",
      "100%|██████████| 712/712 [00:00<00:00, 9046.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import UnifiedTransformerTokenizer\r\n",
    "\r\n",
    "# 设置想要使用模型的名称\r\n",
    "model_name = 'plato-mini'\r\n",
    "tokenizer = UnifiedTransformerTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'position_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "user_input = ['你好啊，你今年多大了']\r\n",
    "\r\n",
    "# 调用dialogue_encode方法生成输入\r\n",
    "encoded_input = tokenizer.dialogue_encode(\r\n",
    "                    user_input,\r\n",
    "                    add_start_token_as_response=True,\r\n",
    "                    return_tensors=True,\r\n",
    "                    is_split_into_words=False)\r\n",
    "\r\n",
    "print(encoded_input.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`dialogue_encode`的详细用法，请参考[dialogue_encode](https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.transformers.unified_transformer.tokenizer.html#paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "与GPT相同，我们可以一键调用UnifiedTransformer预训练模型。\n",
    "\n",
    "[UnifiedTransformer](https://github.com/PaddlePaddle/Knover/tree/luge-dialogue/luge-dialogue)以Transformer的编码器为网络基本组件，采用灵活的注意力机制，十分适合文本生成任务，并在模型输入中加入了标识不同对话技能的special token，使得模型能同时支持闲聊对话、推荐对话和知识对话。\n",
    "\n",
    "PaddleNLP目前为UnifiedTransformer提供了三个中文预训练模型：\n",
    "- `unified_transformer-12L-cn` 该预训练模型是在大规模中文会话数据集上训练得到的\n",
    "- `unified_transformer-12L-cn-luge` 该预训练模型是`unified_transformer-12L-cn`在千言对话数据集上进行微调得到的。\n",
    "- `plato-mini` 该模型使用了十亿级别的中文闲聊对话数据进行预训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-25 23:34:33,400] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/unified_transformer/plato-mini.pdparams and saved to /home/aistudio/.paddlenlp/models/plato-mini\n",
      "[2021-06-25 23:34:33,403] [    INFO] - Downloading plato-mini.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/unified_transformer/plato-mini.pdparams\n",
      "100%|██████████| 530157/530157 [00:09<00:00, 57237.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import UnifiedTransformerLMHeadModel\n",
    "\n",
    "model = UnifiedTransformerLMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下一步我们将处理好的输入传入generate函数，并配置解码策略。\n",
    "\n",
    "这里我们使用的是TopK加sampling的解码策略。即从概率最大的k个结果中按概率进行采样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[20, 15], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[912 , 28  , 3   , 6   , 763 , 1585, 26028, 197 , 3   , 9   , 94  , 16  , 2   , 0   , 0   ],\n",
      "        [6   , 763 , 908 , 26028, 7   , 3   , 6   , 804 , 37  , 2476, 3   , 9   , 94  , 16  , 2   ],\n",
      "        [6   , 763 , 1585, 26028, 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 26028, 7   , 3   , 9   , 42  , 25375, 28  , 16  , 2   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 26028, 3   , 9   , 42  , 25375, 7   , 94  , 16  , 2   , 0   , 0   , 0   ],\n",
      "        [6   , 28  , 763 , 1850, 26028, 197 , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 7   , 3   , 215 , 481 , 17  , 180 , 25397, 25549, 7   , 2   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 26028, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 26028, 197 , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 1017, 26028, 7   , 3   , 9   , 94  , 2   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 215 , 3699, 7   , 3   , 9   , 94  , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1991, 7   , 3   , 255 , 878 , 19  , 25380, 25763, 2   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 26028, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 26028, 7   , 3   , 9   , 94  , 2   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 7   , 3   , 215 , 927 , 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 7   , 3   , 30  , 11  , 25408, 17615, 100 , 3269, 8   , 2   , 0   , 0   ],\n",
      "        [912 , 28  , 3   , 6   , 763 , 215 , 2697, 26028, 7   , 3   , 9   , 94  , 2   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 7   , 3   , 10  , 22  , 4355, 2   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 1585, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ]])\n",
      "Tensor(shape=[20, 1], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[-1.05246007],\n",
      "        [-1.10324085],\n",
      "        [-1.41643369],\n",
      "        [-0.77750635],\n",
      "        [-0.84810710],\n",
      "        [-2.17054057],\n",
      "        [-1.30837619],\n",
      "        [-0.98510933],\n",
      "        [-1.50476301],\n",
      "        [-0.89731610],\n",
      "        [-1.09069228],\n",
      "        [-1.26157188],\n",
      "        [-0.83560562],\n",
      "        [-0.80636698],\n",
      "        [-1.26947320],\n",
      "        [-1.63849485],\n",
      "        [-1.02771103],\n",
      "        [-1.39143252],\n",
      "        [-1.19980919],\n",
      "        [-1.16752601]])\n"
     ]
    }
   ],
   "source": [
    "ids, scores = model.generate(\n",
    "                input_ids=encoded_input['input_ids'],\n",
    "                token_type_ids=encoded_input['token_type_ids'],\n",
    "                position_ids=encoded_input['position_ids'],\n",
    "                attention_mask=encoded_input['attention_mask'],\n",
    "                max_length=64,\n",
    "                min_length=1,\n",
    "                decode_strategy='sampling',\n",
    "                top_k=5,\n",
    "                num_return_sequences=20)\n",
    "\n",
    "print(ids)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/data/vocab.py:220: UserWarning: The type of `to_tokens()`'s input `indices` is not `int` which will be forcibly transfered to `int`. \n",
      "  \"The type of `to_tokens()`'s input `indices` is not `int` which will be forcibly transfered to `int`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我今年23岁了,你多大啊?']\n"
     ]
    }
   ],
   "source": [
    "from utils import select_response\r\n",
    "\r\n",
    "# 简单根据概率选取最佳回复\r\n",
    "result = select_response(ids, scores, tokenizer, keep_space=False, num_return_sequences=20)\r\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "关于生成式API更详细的用法，请参考[generate](https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.transformers.generation_utils.html#paddlenlp.transformers.generation_utils.GenerationMixin.generate)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 下面我们去终端里试试多轮对话吧！\n",
    "\n",
    "PaddleNLP的example中提供了搭建完整对话系统的代码（[人机交互](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/dialogue/unified_transformer#%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92)）。我们可以去终端里尝试一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Paddle+Wechaty\n",
    "\n",
    "开头我们展示的聊天机器人就是使用PaddleHub和Wechaty搭建的。大家可以参照这个教程自己尝试[paddlehub-wechaty-demo](https://github.com/KPatr1ck/paddlehub-wechaty-demo)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上内容实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a0e8ca7743ea4fe9aa741682a63e767f8c48dc55981f4e44a40e0e00d3ab369e)\n",
    "\n",
    "**更多使用方法可参考PaddleNLP教程**\n",
    "\n",
    "- [使用seq2vec模块进行句子情感分类](https://aistudio.baidu.com/aistudio/projectdetail/1283423)\n",
    "- [使用预训练模型ERNIE优化情感分析](https://aistudio.baidu.com/aistudio/projectdetail/1294333)\n",
    "- [使用BiGRU-CRF模型完成快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1317771)\n",
    "- [使用预训练模型ERNIE优化快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1329361)\n",
    "- [使用Seq2Seq模型完成自动对联](https://aistudio.baidu.com/aistudio/projectdetail/1321118)\n",
    "- [使用预训练模型ERNIE-GEN自动写诗](https://aistudio.baidu.com/aistudio/projectdetail/1339888)\n",
    "- [使用TCN网络完成新冠疫情病例数预测](https://aistudio.baidu.com/aistudio/projectdetail/1290873)\n",
    "- [自定义数据集实现文本多分类任务](https://aistudio.baidu.com/aistudio/projectdetail/1468469)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 加入交流群，一起学习吧\n",
    "\n",
    "现在就加入PaddleNLP的QQ技术交流群，一起交流NLP技术吧！\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/d953727af0c24a7c806ab529495f0904f22f809961be420b8c88cdf59b837394\" width=\"200\" height=\"250\" >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
